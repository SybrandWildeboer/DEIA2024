# Workshop Assignments
Welcome to the afternoon session of our workshop on Unlocking the Potential of Large Language Models (LLMs). This session focuses on practical, hands-on experience with LLMs using the OpenAI Playground and Google Colab.

# Schedule
Time: 12:00 PM â€“ 4:30 PM (excluding breaks)
# Assignments:
Building a Retrieval-Augmented Generation (RAG) system using vector stores in OpenAI Playground.
Fine-tuning a language model using a Google Colab notebook.
## Assignment 1: Building a RAG System Using Vector Stores
### Objective
Learn how to enhance language model responses by integrating a vector store to retrieve relevant information, thereby building a Retrieval-Augmented Generation (RAG) system.

### Instructions
Access OpenAI Playground

Log in to the OpenAI Playground: https://platform.openai.com/playground
Introduction to Vector Stores

Familiarize yourself with vector stores by reviewing the documentation:
OpenAI Vector Stores Guide
Data Preparation

Select a Topic: Choose a specific topic of interest for your team.
Gather Documents: Collect example documents related to your topic. You can use the following resources:
Kaggle Datasets: https://www.kaggle.com/datasets
Project Gutenberg: https://www.gutenberg.org/
Wikipedia Article Export: https://en.wikipedia.org/wiki/Special
Ensure Compliance: Verify that the documents comply with ethical guidelines and do not contain disallowed content.
Create a Vector Store

In the Playground, navigate to the vector store section.
Upload Documents: Add your collected documents to create a new vector store.
Generate Embeddings: Use the embedding feature to process your documents.
Query the Vector Store

Develop Queries: Formulate queries relevant to your topic.
Retrieve Information: Use the vector store to find documents that best match your queries.
Integrate with Language Model

Craft Prompts: Incorporate the retrieved information into your prompts.
Generate Responses: Use the language model to generate enriched responses based on the prompts.
Team Discussion

Analyze Results: Evaluate the relevance and accuracy of the generated responses.
Optimize: Experiment with different prompts and retrieval strategies to improve outcomes.
### Resources
OpenAI Playground: https://platform.openai.com/playground
Vector Stores Documentation: OpenAI Vector Stores Guide
### Data Sources:
Kaggle Datasets: https://www.kaggle.com/datasets
Project Gutenberg: https://www.gutenberg.org/
Wikipedia Export: https://en.wikipedia.org/wiki/Special

## Assignment 2: Fine-Tuning a Language Model
### Objective
Understand the process of fine-tuning a language model to perform a specific task, such as Named Entity Recognition (NER), using a pre-prepared Google Colab notebook.

### Instructions
Access the Google Colab Notebook

Notebook Link: Fine-Tuning Notebook
Open in Playground Mode:
Click on "Open in Playground" at the top of the notebook page to work in an editable session without affecting others.
Select a Dataset for Fine-Tuning

Choose a dataset suitable for NER tasks. Examples include:
CoNLL-2003 NER Dataset: GitHub Repository
Kaggle NER Dataset: GitHub Repository
Download the Dataset: Ensure you have the dataset files accessible within the Colab environment.
Prepare the Data

Follow the notebook instructions to format and upload the dataset for fine-tuning.
Ensure that the data complies with OpenAI's policies and ethical guidelines.
Fine-Tune the Model

Run the cells in the notebook to fine-tune the language model on your selected dataset.
Adjust hyperparameters as necessary, but keep coding changes to a minimum.
Evaluate the Fine-Tuned Model

Test the model's performance on a validation set or sample inputs.
Compare the results to the base model to assess improvements.
Team Discussion

Reflect on Findings: Discuss the impact of fine-tuning on model performance.
Ethical Considerations: Consider any ethical implications related to data use and model behavior.
Resources
Fine-Tuning Guide: OpenAI Fine-Tuning Guide
Datasets:
CoNLL-2003 NER Dataset: GitHub Repository
Kaggle NER Dataset: GitHub Repository
Additional Datasets for NER:
WNUT-17 NER Dataset: GitHub Repository
MIT Movie Corpus: GitHub Repository
Team Collaboration Guidelines
One Notebook Per Team: Only one team member needs to run the notebook.
Collaboration: Work together to make decisions and interpret results.
Avoid Interference: Do not access or edit other teams' notebooks.
Ethical Considerations
Data Privacy: Ensure all data used is publicly available and complies with privacy laws.
Content Policy: Avoid using disallowed content as per OpenAI's Usage Policies.
Attribution: Provide proper attribution for any third-party datasets or resources used.
Assistance and Support
Instructor Support: Instructors and assistants are available to help with any questions or issues.
Discussion Encouraged: Share insights and challenges with your team and others.
Accessing the Fine-Tuning Notebook via QR Code
To make it easy to access the fine-tuning notebook, you can use the following link:

Notebook Link: Fine-Tuning Notebook
# Additional Resources
OpenAI API Documentation: https://platform.openai.com/docs/api-reference
OpenAI Cookbook: https://github.com/openai/openai-cookbook
Hugging Face Datasets: https://huggingface.co/datasets